{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - Second part: Machine learning in Spark\n",
    "## Task 2 - SVM with L-BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat task 1 running SVM with the L-BFGS optimization algorithm. Setting the maximum number of iterations to 30 is fine for the purpose of this assignment.\n",
    "\n",
    "Reference: https://spark.apache.org/docs/1.2.0/mllib-optimization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC LBFGS = 0.7272727272727273\n",
      "Area under ROC SGD = 0.6136363636363636\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "import org.apache.spark.mllib.optimization.{LBFGS, HingeGradient, SquaredL2Updater}\n",
    "\n",
    "// Load training data in LIBSVM format.\n",
    "val data = MLUtils.loadLibSVMFile(sc, \"toxicity.txt\")\n",
    "val numFeatures = data.take(1)(0).features.size\n",
    "\n",
    "// Split data into training and test.\n",
    "val splits = data.randomSplit(Array(0.8, 0.2), seed = 11L)\n",
    "val training = splits(0).cache()\n",
    "val test = splits(1)\n",
    "\n",
    "// Create the model with LBFGS\n",
    "val (weightsWithIntercept, _) = LBFGS.runLBFGS(\n",
    "    training.map(x => (x.label, MLUtils.appendBias(x.features))),\n",
    "    new HingeGradient(),\n",
    "    new SquaredL2Updater(),\n",
    "    numCorrections = 10,\n",
    "    convergenceTol = 1e-4,\n",
    "    maxNumIterations = 30,\n",
    "    regParam = 0.01,\n",
    "    initialWeights = Vectors.dense(new Array[Double](numFeatures + 1))\n",
    ")\n",
    "\n",
    "// Run training algorithm to build the model\n",
    "val model2 = new SVMModel(\n",
    "    Vectors.dense(weightsWithIntercept.toArray.slice(0, weightsWithIntercept.size - 1)),\n",
    "    weightsWithIntercept(weightsWithIntercept.size - 1)\n",
    ")\n",
    "val model1 = SVMWithSGD.train(training, 30)\n",
    "\n",
    "// Clear the default threshold.\n",
    "model2.clearThreshold()\n",
    "model1.clearThreshold()\n",
    "\n",
    "// Compute raw scores on the test set.\n",
    "// Compute distance from hyperplane for each test example\n",
    "val scoreAndLabels2 = test.map { point =>\n",
    "  val score = model2.predict(point.features)\n",
    "  (score, point.label)\n",
    "}\n",
    "\n",
    "val scoreAndLabels1 = test.map { point =>\n",
    "  val score = model1.predict(point.features)\n",
    "  (score, point.label)\n",
    "}\n",
    "\n",
    "// Get evaluation metrics.\n",
    "// Compute the area under the ROC curve using the MLlib primitive\n",
    "val metrics2 = new BinaryClassificationMetrics(scoreAndLabels2)\n",
    "val auROC2 = metrics2.areaUnderROC()\n",
    "\n",
    "val metrics1 = new BinaryClassificationMetrics(scoreAndLabels1)\n",
    "val auROC1 = metrics1.areaUnderROC()\n",
    "\n",
    "println(\"Area under ROC LBFGS = \" + auROC2)\n",
    "println(\"Area under ROC SGD = \" + auROC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does L-BFGS perform better than SGD for this training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same training set the L-BFGS `0.727` performs better than SGD `0.614`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache_Toree",
   "language": "",
   "name": "apache_toree"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
