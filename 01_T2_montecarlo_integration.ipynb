{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - First part: Spark development basics\n",
    "## Task 2 - Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.848"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "val n = 1000\n",
    "val count = sc.parallelize(1 to n)\n",
    "  .map { i =>\n",
    "    val x = scala.util.Random.nextFloat\n",
    "    val y = scala.util.Random.nextFloat * 4\n",
    "    val calc = ((1 + scala.math.sin(x)) / scala.math.cos(x))\n",
    "    if (calc > y) 1 else 0\n",
    "  }\n",
    "  .reduce(_+_)\n",
    "  \n",
    "  4.0f*count/n\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Checking the integral at https://www.wolframalpha.com the value there is 1.8418, seems to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Spark's  parallelize  function do? What is it good for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDDs can be created from parallelizing an existing collection in the driver program, or referencing an external  dataset e.g. in an storage system like HDFS.\n",
    "\n",
    "An existing collection (e.g Seq, List) can be parallelized by calling `parallelize` in the driver programm. So the data is loaded into an RDD."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache_Toree",
   "language": "",
   "name": "apache_toree"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
