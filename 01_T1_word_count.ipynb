{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - First part: Spark development basics\n",
    "## Task 1 - Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file:\n",
    "\n",
    "`foo bar bar foo\n",
    "baz foo bar bar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "{\n",
    "sc.textFile(\"input.txt\")\n",
    " .flatMap(_.split(\" \"))\n",
    " .map((_,1))\n",
    " .reduceByKey(_+_)\n",
    " .saveAsTextFile(\"output\")\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks as follows:\n",
    "\n",
    "`(foo,3)\n",
    "(baz,1)\n",
    "(bar,4)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more readable Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val rdd0 = sc.textFile(\"input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val rdd1 = rdd0.flatMap(line => line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val rdd2 = rdd1.map(word => (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val rdd3 = rdd2.reduceByKey((cnt1,cnt2) => cnt1 + cnt2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd3.saveAsTextFile(\"output2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "## What is a  RDD  in Spark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "RDD means *resilient distributed dataset* and is the main data structure in Apache Spark. RDDs are data elements, which are distributed/partitioned over the nodes of a cluster. They are faulty-tolerance and one can operate on it in  parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What are  RDD  transformations and  RDD actions ? How do they differ from each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Transformations** create a new dataset from an existing one. Lazy evaluation is used, so results are not computed right away, but instead Spark remembers set of transformations applied to the dataset. The transformations are only computed when an action requires a result to be returned to the driver program.\n",
    "`map` is an example for a transformation operation.\n",
    "\n",
    "**Actions** do return a value to the driver program after running a computation on the dataset.\n",
    "An example is `reduce`.\n",
    "\n",
    "\n",
    "Transformations returning new RDDs and actions returning a value to the driver programm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache_Toree",
   "language": "",
   "name": "apache_toree"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
